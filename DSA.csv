question,answer
What is time complexity?,Time complexity is a computational complexity that describes the amount of time it takes to run an algorithm as a function of the size of the input. It is usually expressed using Big O notation.
What is space complexity?,Space complexity is the amount of memory space an algorithm uses in relation to the size of the input. It is also typically expressed using Big O notation.
What is the difference between time complexity and space complexity?,"Time complexity measures the amount of time an algorithm takes to run, while space complexity measures the amount of memory it consumes. Both are important for evaluating the efficiency of algorithms."
What is Big O notation?,"Big O notation is a mathematical notation used to describe the upper bound of an algorithm’s runtime or space usage in terms of the size of the input. It provides an asymptotic upper limit, describing the worst-case scenario. If f(n) describes the running time of an algorithm, f(n) is O(g(n)) if there exist a positive constant C and n such that, 0 ≤ f(n) ≤ cg(n) for all n ≥ n 0 0"
What is Omega (Ω) notation?,"Omega (Ω) notation is used to describe the best-case or lower bound of an algorithm's performance. It provides an asymptotic lower limit, representing the minimum time or space required for an algorithm. Let g and f be the function from the set of natural numbers to itself. The function f is said to be Ω(g), if there is a constant c > 0 and a natural number n such that c*g(n) ≤ 0 f(n) for all n ≥ n 0"
What is Theta (Θ) notation?,"Theta (Θ) notation provides a tight bound on the time or space complexity of an algorithm. It describes the runtime or space requirement in both the best and worst cases, giving a more precise estimate. Let g and f be the function from the set of natural numbers to itself. The function f is said to be Θ(g), if there are constants c , c > 0 and a natural number n such that c * g(n) 1 2 0 1 ≤ f(n) ≤ c * g(n) for all n ≥ n . 2 0"
What is the time complexity of linear search?,"The time complexity of linear search is O(n), where n is the number of elements in the array. This is because the algorithm needs to check each element until it finds the target or reaches the end. 1"
What is the time complexity of binary search?,"The time complexity of binary search is O(log n), where n is the number of elements. It works by dividing the search space in half with each iteration, making it more efficient than linear search."
What is the space complexity of linear search?,"The space complexity of linear search is O(1), since it only requires a constant amount of extra space for variables like the target element."
What is the space complexity of binary search?,"The space complexity of binary search is O(1), as it operates on the array directly and does not require extra space besides variables for low, high, and mid indices."
What is the difference between linear search and binary search?,"Linear search scans each element of an array one by one to find the target, while binary search works by repeatedly dividing the search space in half. Binary search is more efficient but requires the array to be sorted."
Explain the concept of bubble sort.,"Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The process is repeated until the array is sorted."
What is the time complexity of bubble sort in the worst case?,The worst-case time complexity of bubble sort is O(n²) because the algorithm may need to compare and swap each pair of elements in the array multiple times.
What is the best-case time complexity of bubble sort?,"The best-case time complexity of bubble sort is O(n), which occurs when the array is already sorted. In this case, the algorithm only needs one pass through the array to confirm no swaps are needed."
How can you optimize bubble sort?,"Bubble sort can be optimized by adding a flag to detect if any swaps were made during a pass. If no swaps are made, the algorithm can terminate early, improving efficiency for nearly sorted arrays."
What is the time complexity of selection sort?,The time complexity of selection sort is O(n²) because it requires two 2 nested loops: one to find the minimum element and another to perform the swaps.
What is the space complexity of selection sort?,The space complexity of selection sort is O(1) because it sorts the array in place and uses only a constant amount of extra space.
What is the concept of insertion sort?,Insertion sort is a simple sorting algorithm that builds the sorted array one element at a time by repeatedly picking the next element and inserting it into its correct position in the sorted portion of the array.
What is the time complexity of insertion sort in the worst case?,"The worst-case time complexity of insertion sort is O(n²) when the array is sorted in reverse order, requiring the algorithm to shift elements for each insertion."
What is the best-case time complexity of insertion sort?,"The best-case time complexity of insertion sort is O(n) when the array is already sorted, as the algorithm only needs to traverse the array once."
What is merge sort?,"Merge sort is a divide-and-conquer sorting algorithm that divides the array into two halves, recursively sorts each half, and then merges the sorted halves to produce the final sorted array."
What is the time complexity of merge sort?,The time complexity of merge sort is O(n log n) in both the best and worst cases because the array is recursively divided into halves and then merged.
What is the space complexity of merge sort?,The space complexity of merge sort is O(n) because it requires additional space for storing the temporary arrays during the merge step.
What is quicksort?,"QuickSort is a divide-and-conquer algorithm that selects a pivot element, partitions the array into elements smaller than the pivot and elements greater than the pivot, and recursively sorts the subarrays."
What is the time complexity of quicksort in the best case?,"The best-case time complexity of QuickSort is O(n log n), which occurs when the pivot divides the array into two roughly equal subarrays. 3"
What is the time complexity of quicksort in the worst case?,"The worst-case time complexity of QuickSort is O(n²), which occurs when the pivot always divides the array into highly unbalanced subarrays (e.g., when the array is already sorted or nearly sorted)."
What is heap sort?,"Heap sort is a comparison-based sorting algorithm that builds a max- heap (or min-heap), then repeatedly extracts the root element (the largest or smallest) and reconstructs the heap until the array is sorted."
What is the time complexity of heap sort?,"The time complexity of heap sort is O(n log n) in both the worst and best cases because building the heap takes O(n), and each extraction operation takes O(log n)."
What is the space complexity of heap sort?,"The space complexity of heap sort is O(1) because it sorts the array in place, without requiring additional space."
What is radix sort?,"Radix Sort is a non-comparative sorting algorithm that sorts numbers digit by digit, starting from the least significant digit to the most significant digit, using a stable sorting algorithm like counting sort for each digit."
What is the time complexity of radix sort?,"The time complexity of radix sort is O(nk), where n is the number of elements in the array and k is the number of digits in the largest number."
What is the space complexity of radix sort?,"The space complexity of radix sort is O(n + k), where n is the number of elements in the array and k is the range of the digits."
What is counting sort?,Counting sort is a non-comparative sorting algorithm that counts the frequency of each element in the array and then places each element in its correct position based on the frequencies.
What is the time complexity of counting sort?,"The time complexity of counting sort is O(n + k), where n is the number of elements and k is the range of input values. 4"
What is bucket sort?,"Bucket sort is a non-comparative sorting algorithm that divides the array into several buckets, sorts each bucket individually using another sorting algorithm (like insertion sort), and then combines the sorted buckets."
What is the time complexity of bucket sort?,"The time complexity of bucket sort is O(n + k), where n is the number of elements and k is the number of buckets."
What is binary search tree (BST)?,"A Binary Search Tree is a binary tree in which each node has at most two children, and the left child has a smaller key while the right child has a larger key, allowing for efficient searching, insertion, and deletion."
What is the time complexity of searching in a binary search tree?,"The time complexity of searching in a binary search tree is O(log n) in the best case, assuming the tree is balanced. In the worst case (unbalanced), it can be O(n)."
What is AVL tree?,An AVL Tree is a self-balancing binary search tree where the height difference between the left and right subtrees of every node is at most one. Rotations are used to maintain balance during insertions and deletions.
What is the time complexity of insertion in an AVL tree?,"The time complexity of insertion in an AVL tree is O(log n) because the tree remains balanced after each insertion, ensuring logarithmic height."
What is the time complexity of deletion in an AVL tree?,"The time complexity of deletion in an AVL tree is O(log n) because the tree is balanced after each deletion, ensuring that the height remains logarithmic, and rebalancing operations (rotations) are performed in O(log n) time."
What is the concept of heap in computer science?,"A heap is a complete binary tree that satisfies the heap property. In a max-heap, the value of each node is greater than or equal to the values of its children, and in a min-heap, the value of each node is less than or equal to the values of its children."
What is the difference between a max-heap and a min-heap?,"In a max-heap, the root node contains the maximum value, and every parent node has a value greater than or equal to its children. In a min-heap, the 5 root node contains the minimum value, and every parent node has a value less than or equal to its children."
What is the time complexity of building a heap?,The time complexity of building a heap is O(n) because the process of building a heap involves reordering the elements starting from the lowest level to the root.
What is the time complexity of heap sort?,"The time complexity of heap sort is O(n log n), as it involves building a heap in O(n) time and then repeatedly extracting the maximum or minimum element (which takes O(log n) time)."
What is Dijkstra’s Algorithm?,Dijkstra’s Algorithm is a shortest-path algorithm used to find the shortest path from a source node to all other nodes in a weighted graph. It works by iteratively selecting the node with the smallest tentative distance and updating its neighbours.
What is the time complexity of Dijkstra's algorithm using a priority queue?,"The time complexity of Dijkstra's algorithm using a priority queue (min-heap) is O((V + E) log V), where V is the number of vertices and E is the number of edges. This is because for each vertex and edge, the algorithm performs priority queue operations that take O(log V) time."
What is Bellman-Ford Algorithm?,"Bellman-Ford Algorithm is a shortest-path algorithm that works for graphs with negative weights. It iteratively relaxes all edges, updating the shortest path estimates until the algorithm converges. It can also detect negative weight cycles."
What is the time complexity of the Bellman-Ford algorithm?,"The time complexity of the Bellman-Ford algorithm is O(VE), where V is the number of vertices and E is the number of edges. This is because each edge is relaxed up to V-1 times."
What is Floyd-Warshall Algorithm?,The Floyd-Warshall algorithm is an all-pairs shortest path algorithm used to find the shortest paths between all pairs of vertices in a weighted graph. It works by iteratively updating the shortest paths between all pairs of nodes. 6
What is the time complexity of the Floyd-Warshall algorithm?,"The time complexity of the Floyd-Warshall algorithm is O(V³), where V is the number of vertices. This is because it uses three nested loops to check and update all pairs of vertices."
What is a minimum spanning tree (MST)?,"A Minimum Spanning Tree is a subset of edges from a connected, undirected graph that connects all the vertices without cycles and has the minimum possible total edge weight."
What is Prim’s Algorithm?,Prim’s algorithm is a greedy algorithm that finds the minimum spanning tree of a connected graph. It starts with an arbitrary vertex and grows the MST by adding the smallest edge that connects a vertex in the MST to a vertex outside of it.
What is the time complexity of Prim’s Algorithm using a priority queue?,"The time complexity of Prim’s algorithm using a priority queue (min- heap) is O((V + E) log V), where V is the number of vertices and E is the number of edges."
What is Kruskal’s Algorithm?,"Kruskal’s algorithm is another greedy algorithm for finding the minimum spanning tree of a graph. It sorts all edges by weight and adds them one by one to the MST, ensuring no cycles are formed."
What is the time complexity of Kruskal’s Algorithm?,"The time complexity of Kruskal’s algorithm is O(E log E), where E is the number of edges, as the edges are sorted before being added to the MST."
What is topological sorting?,"Topological sorting is the linear ordering of vertices in a directed graph such that for every directed edge from vertex u to vertex v, u comes before v in the ordering. It is applicable only for Directed Acyclic Graphs (DAGs)."
What is the time complexity of topological sorting using DFS?,"The time complexity of topological sorting using DFS is O(V + E), where V is the number of vertices and E is the number of edges in the graph."
What is dynamic programming (DP)?,"Dynamic programming is a method for solving problems by breaking 7 them down into simpler subproblems, solving each subproblem once, and storing the results to avoid redundant computations."
What is memoization in dynamic programming?,"Memoization is a technique used in dynamic programming where the results of expensive function calls are stored, so the same computation is not repeated multiple times."
What is the time complexity of the Longest Common Subsequence (LCS) problem?,"The time complexity of solving the Longest Common Subsequence (LCS) problem using dynamic programming is O(m * n), where m and n are the lengths of the two strings."
What is the 0/1 Knapsack problem?,"The 0/1 Knapsack problem is a classic optimization problem in which we are given a set of items, each with a weight and a value, and a knapsack with a weight limit. The objective is to find the maximum value that can be carried in the knapsack without exceeding the weight limit."
What is the time complexity of solving the 0/1 Knapsack problem using dynamic programming?,"The time complexity of solving the 0/1 Knapsack problem using dynamic programming is O(nW), where n is the number of items and W is the maximum weight capacity of the knapsack."
What is matrix chain multiplication?,Matrix Chain Multiplication is an optimization problem in which the goal is to determine the most efficient way to multiply a sequence of matrices. The order in which matrices are multiplied affects the number of operations required.
What is the time complexity of solving the Matrix Chain Multiplication problem using dynamic programming?,"The time complexity of solving the Matrix Chain Multiplication problem using dynamic programming is O(n³), where n is the number of matrices."
What is the Activity Selection Problem?,"The Activity Selection Problem is an optimization problem in which we are given a set of activities, each with a start time and end time, and the goal is to select the maximum number of activities that don’t overlap. 8"
What is the time complexity of solving the Activity Selection Problem using a greedy algorithm?,"The time complexity of solving the Activity Selection Problem using a greedy algorithm is O(n log n), where n is the number of activities, because sorting the activities by their end time is the most computationally expensive step."
What is Huffman Encoding?,Huffman Encoding is a lossless data compression algorithm that uses a variable-length prefix coding scheme. It assigns shorter codes to more frequent characters and longer codes to less frequent characters.
What is the time complexity of building the Huffman tree?,"The time complexity of building the Huffman tree is O(n log n), where n is the number of symbols or characters in the input."
What is the time complexity of the job scheduling problem using a greedy approach?,"The time complexity of solving the Job Scheduling Problem using a greedy algorithm is O(n log n), where n is the number of jobs, as the algorithm first sorts the jobs by their deadlines or start times before scheduling them."
What is the N-Queens Problem?,"The N-Queens Problem is a classic combinatorial problem where the goal is to place N queens on an N x N chessboard such that no two queens threaten each other. This means no two queens can share the same row, column, or diagonal."
What is the time complexity of the N-Queens problem using backtracking?,"The time complexity of the N-Queens problem using backtracking is O(N!) because, in the worst case, the algorithm explores every possible arrangement of queens on the board."
What is the Sudoku Solver problem?,"The Sudoku Solver problem is a constraint satisfaction problem where the objective is to fill a 9x9 Sudoku grid with numbers from 1 to 9 such that each row, column, and 3x3 subgrid contains all the digits from 1 to 9 without repetition."
What is the time complexity of solving Sudoku using backtracking?,"The time complexity of solving Sudoku using backtracking is 9 O(9^(N×N)), where N is the size of the grid (in a standard 9x9 Sudoku, N = 9). This is because the backtracking algorithm tries filling each cell with each possible number."
What is the Subset Sum Problem?,"The Subset Sum Problem is a classic problem where given a set of integers, the goal is to determine if there is a subset whose sum equals a given target sum."
What is the time complexity of solving the Subset Sum Problem using dynamic programming?,"The time complexity of solving the Subset Sum Problem using dynamic programming is O(n × S), where n is the number of elements in the set and S is the target sum."
What is hashing in computer science?,"Hashing is a technique used to map data to a fixed-size value, called a hash code, using a hash function. Hashing is commonly used in data structures like hash tables to quickly retrieve, insert, or delete data."
What are hash functions?,"A hash function is a function that takes an input (or key) and returns a fixed-size string of bytes, typically a hash code. The function should ideally distribute inputs uniformly across the hash table, minimizing collisions."
What is a hash collision?,"A hash collision occurs when two different inputs produce the same hash code. This can cause problems in hash-based data structures like hash tables, where unique keys are expected."
What is chaining in hash tables?,"Chaining is a collision resolution technique in hash tables where each slot of the hash table is a linked list (or another data structure). If multiple elements hash to the same index, they are added to the linked list at that index."
What is open addressing in hash tables?,"Open addressing is another collision resolution technique where all elements are stored directly in the hash table array. When a collision occurs, the algorithm probes the next available slot according to a predefined probe sequence (like linear probing, quadratic probing, or double hashing)."
What is the time complexity of searching in a hash table with chaining? 10,"The time complexity of searching in a hash table with chaining is O(1) on average, but it can degrade to O(n) in the worst case when all elements hash to the same slot, forming a linked list."
What is the time complexity of searching in a hash table with open addressing?,"The time complexity of searching in a hash table with open addressing is O(1) on average, but it can degrade to O(n) in the worst case when the table becomes highly loaded or requires many probes."
What is the load factor in hash tables?,The load factor of a hash table is the ratio of the number of elements stored in the table to the total number of slots (capacity) in the table. A higher load factor increases the chance of collisions.
How do you handle collisions in a hash table?,Collisions in a hash table can be handled using methods like chaining (storing multiple values in a linked list or another structure) or open addressing (probing for the next available slot).
What is the difference between a linear search and a binary search?,"Linear search is a simple search algorithm that checks each element in a list one by one until the target is found or the list ends. Binary search, on the other hand, is a more efficient search algorithm that works on sorted arrays by repeatedly dividing the search interval in half."
What is the time complexity of linear search?,"The time complexity of linear search is O(n), where n is the number of elements in the list, as it may need to check every element."
What is the time complexity of binary search?,"The time complexity of binary search is O(log n), where n is the number of elements in the sorted array. This is because the search interval is halved with each comparison."
Can binary search be used on unsorted arrays?,"No, binary search requires the array to be sorted. If the array is not sorted, binary search will not work correctly."
What is the difference between bubble sort and selection sort?,"Bubble sort works by repeatedly swapping adjacent elements if they 11 are in the wrong order, while selection sort works by selecting the smallest (or largest) element and swapping it with the first unsorted element."
What is the time complexity of bubble sort?,"The time complexity of bubble sort is O(n²), where n is the number of elements in the array. This is because it compares and swaps elements in a nested loop."
What is the time complexity of selection sort?,"The time complexity of selection sort is O(n²), where n is the number of elements in the array. It uses two nested loops: one to select the smallest (or largest) element and another to swap it."
What is the time complexity of insertion sort?,"The time complexity of insertion sort is O(n²) in the worst and average cases, but O(n) in the best case when the array is already sorted. It works by inserting each element into its correct position in the sorted part of the array."
What is the time complexity of merge sort?,"The time complexity of merge sort is O(n log n), where n is the number of elements. It divides the array into two halves and recursively sorts each half, followed by merging the sorted halves."
What is the time complexity of quicksort?,"The average-case time complexity of quicksort is O(n log n), where n is the number of elements, but in the worst case, it is O(n²) if the pivot selection is poor (e.g., always choosing the smallest or largest element as the pivot)."
What is the time complexity of heap sort?,"The time complexity of heap sort is O(n log n), where n is the number of elements. It involves building a heap in O(n) time and then repeatedly extracting the maximum element in O(log n) time."
What is counting sort?,Counting sort is a non-comparative sorting algorithm that works by counting the occurrences of each element in the input and using this count to place elements in their correct position in the sorted array. It is effective when the range of input values is small.
What is the time complexity of counting sort?,"The time complexity of counting sort is O(n + k), where n is the number of elements and k is the range of the input values. It is a linear time sorting algorithm when k is not significantly larger than n. 12"
What is radix sort?,Radix sort is a non-comparative integer sorting algorithm that processes each digit of the numbers starting from the least significant digit (LSD) or the most significant digit (MSD). It uses a stable sorting algorithm (like counting sort) at each digit.
What is the time complexity of radix sort?,"The time complexity of radix sort is O(n * k), where n is the number of elements in the array and k is the number of digits in the largest number (or the range of the elements). This makes it efficient for sorting numbers with a small range or fixed number of digits."
What is bucket sort?,"Bucket sort is a comparison-free sorting algorithm that divides the input into a finite number of equally-sized ""buckets."" Each bucket is sorted individually, often using another sorting algorithm like insertion sort, and the final sorted array is formed by concatenating the sorted buckets."
What is the time complexity of bucket sort?,"The time complexity of bucket sort is O(n + k), where n is the number of elements and k is the number of buckets. Bucket sort performs well when the input elements are uniformly distributed over a range."
When is bucket sort the most efficient?,Bucket sort is most efficient when the input values are uniformly distributed over a small range and the number of elements is large. It avoids the quadratic time complexity of comparison-based algorithms.
What is the best-case time complexity of quicksort?,"The best-case time complexity of quicksort is O(n log n). This occurs when the pivot chosen divides the array into two nearly equal parts, ensuring efficient partitioning at each recursion level."
What is the worst-case time complexity of quicksort?,"The worst-case time complexity of quicksort is O(n²), which occurs when the pivot chosen is always the smallest or largest element, leading to unbalanced partitions (e.g., sorting an already sorted array)."
How can you improve the performance of quicksort?,"The performance of quicksort can be improved by using a good pivot selection strategy, such as choosing a random pivot, the median of three 13 elements, or using the ""introselect"" algorithm for hybrid approaches that switch to heapsort or insertion sort when the recursion depth becomes too large."
What is merge sort’s space complexity?,"The space complexity of merge sort is O(n), where n is the number of elements in the array. This is because merge sort requires additional space to store temporary arrays during the merging process."
What is the advantage of merge sort over quicksort?,"The main advantage of merge sort over quicksort is that merge sort guarantees a time complexity of O(n log n) in all cases, while quicksort's time complexity can degrade to O(n²) in the worst case. Merge sort is also stable, making it suitable for sorting items with duplicate keys."
What is the purpose of heap sort?,"Heap sort is an in-place, comparison-based sorting algorithm that uses a binary heap data structure. It is used to sort an array by repeatedly extracting the maximum (or minimum) element from the heap and placing it at the correct position in the array."
What is the time complexity of heap sort?,"The time complexity of heap sort is O(n log n), where n is the number of elements. It builds the heap in O(n) time and performs O(log n) operations to remove the maximum element from the heap repeatedly."
What are the differences between selection sort and insertion sort?,"Selection sort repeatedly selects the smallest (or largest) element and places it in the correct position, while insertion sort builds the sorted portion of the array incrementally by inserting elements into their correct position. Selection sort makes fewer swaps but has a higher number of comparisons, while insertion sort typically performs better when the array is nearly sorted."
What is the time complexity of insertion sort in the worst case?,"The time complexity of insertion sort in the worst case is O(n²), where n is the number of elements. This happens when the input array is in reverse order, and every element needs to be compared and shifted."
What is the space complexity of insertion sort?,"The space complexity of insertion sort is O(1), as it is an in-place sorting algorithm that does not require any additional memory outside of the input array. 14"
What is the best-case time complexity of bubble sort?,"The best-case time complexity of bubble sort is O(n), which occurs when the array is already sorted. In this case, the algorithm can detect that no swaps are needed after one pass and terminate early."
What is the worst-case time complexity of bubble sort?,"The worst-case time complexity of bubble sort is O(n²), where n is the number of elements in the array. This occurs when the array is sorted in reverse order and every element needs to be swapped in each pass."
What is the time complexity of counting sort when the range of input values is large?,"The time complexity of counting sort is O(n + k), where n is the number of elements in the input and k is the range of the input values. When k is much larger than n, the algorithm becomes inefficient, making counting sort unsuitable for large ranges."
What is the difference between counting sort and radix sort?,"Counting sort is a non-comparative sorting algorithm that counts the occurrences of each element, whereas radix sort processes each digit of the numbers. Radix sort uses counting sort as a subroutine at each digit level."
What is the key observation for the use of radix sort?,"Radix sort is effective when the elements to be sorted are integers or strings that have a fixed number of digits (or characters). It leverages the number of digits (or characters) rather than comparing the entire numbers or strings, making it efficient in certain cases."
How does merge sort work?,"Merge sort works by recursively dividing the array into two halves, sorting each half, and then merging the sorted halves back together. The merging process ensures that the final array is sorted."
What is the concept of divide and conquer in sorting algorithms?,"Divide and conquer is a paradigm in which a problem is divided into smaller subproblems, each of which is solved recursively. The results of the subproblems are then combined to solve the original problem. Sorting algorithms like merge sort and quicksort use this paradigm to divide an array and combine the sorted portions."
How does quicksort partition the array?,"In quicksort, a pivot element is selected, and the array is partitioned 15 into two subarrays: one with elements smaller than the pivot and the other with elements larger than the pivot. The pivot is then placed in its final sorted position. This process is recursively applied to the subarrays."
What is the pivot selection strategy in quicksort?,"In quicksort, the pivot selection strategy can vary. Common strategies include picking the first element, the last element, the middle element, or selecting a random element. A good pivot selection strategy helps avoid the worst-case time complexity of O(n²)."
What are the advantages of heap sort?,"The main advantages of heap sort are that it has a time complexity of O(n log n) in all cases (worst, average, and best), is an in-place sorting algorithm, and does not require additional space like merge sort."
What is the disadvantage of heap sort compared to merge sort?,"While heap sort has a time complexity of O(n log n), it is not stable, meaning that it may not preserve the order of equal elements. Merge sort, on the other hand, is stable and guarantees to maintain the relative order of equal elements."
What is the significance of a stable sorting algorithm?,A stable sorting algorithm preserves the relative order of records with equal keys. This is important when sorting complex data structures where the order of equal elements should be maintained.
What are the conditions under which merge sort can be slower than quicksort?,"Merge sort can be slower than quicksort when the system has limited memory or the input array is small. This is because merge sort requires additional space for merging, whereas quicksort is an in-place algorithm that performs better in these situations."
What is a comparison-based sorting algorithm?,"A comparison-based sorting algorithm sorts an array by comparing elements and determining their relative order. Examples include merge sort, quicksort, bubble sort, and insertion sort."
What is the best-case scenario for quicksort?,"The best-case scenario for quicksort occurs when the pivot element divides the array into two nearly equal parts, resulting in the most balanced recursion and achieving a time complexity of O(n log n). 16"
What is the worst-case scenario for merge sort?,"Merge sort’s worst-case time complexity is also O(n log n), making it a reliable sorting algorithm that performs consistently well."
What is the time complexity of linear search?,"The time complexity of linear search is O(n), where n is the number of elements in the array. This is because, in the worst case, the algorithm needs to check each element of the array one by one."
What is the best-case time complexity of linear search?,"The best-case time complexity of linear search is O(1), which occurs when the target element is the first element of the array."
What is the time complexity of binary search?,"The time complexity of binary search is O(log n), where n is the number of elements in the array. This is because binary search repeatedly divides the search space in half."
What is the condition for binary search to work?,"Binary search works only on a sorted array. It relies on the fact that the middle element divides the array into two halves, allowing the search space to be reduced by half after each iteration."
How does binary search divide the array?,"In binary search, the array is divided by comparing the target element with the middle element of the array. If the target is smaller, the search continues in the left half; if it is larger, the search continues in the right half. This process repeats until the target is found or the search space is empty."
What happens if the target element is not found in binary search?,"If the target element is not found in binary search, the algorithm returns a value indicating that the element is absent, such as -1 or null."
What is the space complexity of binary search?,"The space complexity of binary search is O(1) in the iterative version, as it uses a constant amount of space. If implemented recursively, the space complexity is O(log n) due to the recursive call stack."
What is the key difference between binary search and linear search?,"The key difference is that binary search is faster with a time complexity of O(log n), but it requires the array to be sorted. Linear search, on 17 the other hand, works on unsorted arrays but has a slower time complexity of O(n)."
What is the worst-case time complexity of quicksort?,"The worst-case time complexity of quicksort is O(n²), which happens when the pivot selection leads to unbalanced partitions. For example, when the pivot is always the smallest or largest element in a sorted or reverse-sorted array."
How can you mitigate the worst-case time complexity of quicksort?,"The worst-case time complexity of quicksort can be mitigated by using a good pivot selection strategy, such as choosing a random pivot, using the median of three elements, or using introspective sort (a hybrid of quicksort and heapsort)."
Why is merge sort considered a stable sorting algorithm?,"Merge sort is stable because, during the merging process, if two elements are equal, they retain their relative order from the input array. This property ensures that duplicate elements remain in their original order after sorting."
What are the characteristics of a stable sorting algorithm?,"A stable sorting algorithm preserves the relative order of elements with equal values. For example, if two elements A and B are equal in value and A appears before B in the original array, A will still appear before B after sorting."
What is the difference between selection sort and insertion sort?,"Selection sort selects the minimum element and places it in its correct position by swapping it with the element at the beginning of the unsorted part. Insertion sort, on the other hand, builds the sorted part of the array incrementally by inserting each element into its correct position within the sorted portion."
What is the time complexity of bubble sort in the best case?,"The best-case time complexity of bubble sort is O(n), which occurs when the array is already sorted. In this case, the algorithm detects that no swaps are needed and terminates early."
Why is bubble sort considered inefficient for large datasets?,"Bubble sort is inefficient for large datasets because it has a time 18 complexity of O(n²) in the worst and average cases. This quadratic time complexity results in a large number of comparisons and swaps, making it slower than more efficient algorithms like quicksort and merge sort."
What is the key advantage of insertion sort?,The key advantage of insertion sort is that it performs well on small or nearly sorted arrays. It has a best-case time complexity of O(n) when the array is already sorted and is an in-place sorting algorithm that doesn't require additional memory.
How does selection sort work?,Selection sort works by repeatedly selecting the minimum element from the unsorted portion of the array and swapping it with the first unsorted element. This process continues until the entire array is sorted.
What is the space complexity of merge sort?,"The space complexity of merge sort is O(n), where n is the number of elements in the array. This is because merge sort requires additional space to store temporary arrays during the merging process."
What is the main disadvantage of heap sort?,"The main disadvantage of heap sort is that it is not a stable sorting algorithm. It may change the relative order of elements with equal values, unlike merge sort which is stable."
How does heap sort build a heap?,"Heap sort builds a heap by arranging the elements of the array into a binary heap. It first constructs a max heap (or min heap, depending on the sorting order) by repeatedly applying the heapify operation from the bottom-up."
What is heapify in heap sort?,"Heapify is a process used in heap sort to ensure that a binary tree satisfies the heap property. In a max heap, every parent node must be greater than or equal to its children, while in a min heap, every parent node must be less than or equal to its children."
What is the worst-case time complexity of insertion sort?,"The worst-case time complexity of insertion sort is O(n²), which occurs when the input array is in reverse order and every element needs to be compared and shifted to its correct position."
What is the space complexity of counting sort?,"The space complexity of counting sort is O(k), where k is the range of 19 the input values. Counting sort requires additional space to maintain a count of occurrences for each possible value in the input."
What is the time complexity of counting sort when the input range is small?,"When the input range is small, the time complexity of counting sort is O(n + k), where n is the number of elements and k is the range of the input. In practice, if k is much smaller than n, counting sort can be very efficient."
How does radix sort differ from other comparison-based sorting algorithms?,"Radix sort differs from other comparison-based sorting algorithms because it does not compare elements directly. Instead, it sorts elements based on their individual digits or characters, processing each digit in turn from the least significant to the most significant (or vice versa)."
What is the time complexity of radix sort when the input array is large?,"The time complexity of radix sort is O(n * k), where n is the number of elements in the array and k is the number of digits or characters. For large inputs with a small range of digits, radix sort can be faster than comparison- based algorithms."
Why is quicksort more efficient than bubble sort?,"Quicksort is more efficient than bubble sort because it has a time complexity of O(n log n) in the average case, while bubble sort has a time complexity of O(n²). Quicksort uses a divide-and-conquer approach that reduces the problem size exponentially, while bubble sort repeatedly compares adjacent elements."
What is the impact of pivot selection in quicksort?,"Pivot selection is crucial in quicksort because it determines how evenly the array is divided into subarrays. A poor pivot selection (e.g., always choosing the smallest or largest element) can lead to unbalanced partitions, increasing the likelihood of the algorithm running in O(n²) time."
What is the primary purpose of heap sort?,"The primary purpose of heap sort is to efficiently sort an array by building a binary heap and repeatedly extracting the maximum (or minimum) element, placing it in its correct position in the array. It has a time complexity of O(n log n) and works in place. 20"
What is the relationship between merge sort and divide-and- conquer?,"Merge sort is an example of the divide-and-conquer strategy. It divides the array into smaller subarrays, recursively sorts them, and then merges the sorted subarrays back together. The problem is broken down into smaller subproblems that are solved independently before combining the results."
Why is bubble sort considered inefficient on large datasets?,"Bubble sort is inefficient on large datasets because of its quadratic time complexity of O(n²), which results in a large number of comparisons and swaps. It is much slower compared to more efficient algorithms like quicksort and merge sort."
What is the space complexity of quicksort?,"The space complexity of quicksort is O(log n) in the best case, which occurs when the pivot selection divides the array evenly. In the worst case, the space complexity can be O(n) if the array is heavily unbalanced (e.g., when the pivot is always the smallest or largest element)."
How does counting sort handle negative numbers?,"Counting sort assumes that all input elements are non-negative integers. To handle negative numbers, you would need to adjust the algorithm by shifting the range of the input to make all numbers non-negative, by adding a constant value to each element."
What is the time complexity of merge sort in the worst case?,"The time complexity of merge sort in the worst case is O(n log n). This is because the array is repeatedly divided in half (log n divisions), and merging the subarrays takes linear time (O(n))."
What is the space complexity of quicksort?,"The space complexity of quicksort is O(log n) in the average case when implemented recursively. This is due to the call stack used by the recursion. However, in the worst case, it could be O(n) if the recursion depth is too deep."
What is the key difference between quicksort and merge sort?,"The key difference is that quicksort is an in-place sorting algorithm, meaning it doesn't require extra space for an auxiliary array, while merge sort requires extra space for merging subarrays. Additionally, quicksort has a faster average time complexity (O(n log n)) compared to merge sort in practice, though merge sort has a more consistent performance. 21"
Why is quicksort preferred over other sorting algorithms in many cases?,"Quicksort is often preferred because of its average-case time complexity of O(n log n), which is generally faster than other algorithms like bubble sort, selection sort, or insertion sort. It is also an in-place sorting algorithm, requiring only a small amount of additional memory."
How does merge sort handle large datasets?,"Merge sort handles large datasets effectively because it has a time complexity of O(n log n), which scales better than algorithms with quadratic time complexities, like bubble sort. However, it requires O(n) extra space to store the temporary subarrays during the merge process, making it less memory efficient."
What are the advantages of heap sort over quicksort?,"Heap sort has a worst-case time complexity of O(n log n), making it more predictable than quicksort, which can degrade to O(n²) in the worst case. Heap sort is also an in-place sorting algorithm, meaning it does not require additional memory like merge sort. However, it is not a stable sort, unlike merge sort."
How do you perform an in-place merge in merge sort?,"While merge sort typically requires an auxiliary array to merge the subarrays, performing an in-place merge can be done using techniques like the ""two-pointer technique,"" where elements are swapped between the subarrays to merge them without using extra space. However, an in-place merge is more complex and slower than the typical merge method."
What is a stable sorting algorithm?,"A stable sorting algorithm preserves the relative order of elements with equal values. For example, if two elements have the same value and one appears before the other in the original list, they will remain in the same order after sorting. Examples of stable sorting algorithms include merge sort and bubble sort."
Why is merge sort considered a stable sorting algorithm?,"Merge sort is considered stable because, during the merging process, if two elements are equal, they are placed in the merged array in the order they appeared in the original array. This ensures that their relative order is preserved."
What is the purpose of the partition step in quicksort?,"The partition step in quicksort is used to divide the array into two subarrays around a pivot element. The elements smaller than the pivot are 22 placed on one side, and the elements larger than the pivot are placed on the other side. This step helps to reduce the search space for the next recursive call."
Can you describe the heap property in a binary heap?,"The heap property ensures that a binary heap satisfies the following conditions: In a max-heap, the value of each parent node is greater than or equal to its children. In a min-heap, the value of each parent node is less than or equal to its children. This property is crucial for efficiently extracting the maximum or minimum element in the heap."
What is the worst-case time complexity of bubble sort?,"The worst-case time complexity of bubble sort is O(n²). This occurs when the input array is sorted in reverse order, requiring a large number of comparisons and swaps."
What is the best-case time complexity of insertion sort?,"The best-case time complexity of insertion sort is O(n). This occurs when the array is already sorted, and no shifting of elements is needed."
How do you implement a priority queue using a binary heap?,A priority queue can be implemented using a binary heap by using the heap property to efficiently extract the element with the highest (or lowest) priority. The heap supports insertion in O(log n) time and extraction of the maximum or minimum element in O(log n) time.
What is the time complexity of radix sort?,"The time complexity of radix sort is O(n * k), where n is the number of elements in the array and k is the number of digits or characters in the input. If the number of digits is small compared to the number of elements, radix sort can be more efficient than comparison-based algorithms like quicksort."
How does radix sort work for sorting strings?,"Radix sort can be used to sort strings by treating each string as a sequence of characters. The algorithm processes the strings digit by digit (or character by character), starting from the least significant digit and moving to the most significant one, sorting the strings by each character at each pass."
What are the limitations of counting sort?,"The limitations of counting sort include: It only works for integer values within a fixed range. It requires additional memory proportional to the range of input values, which can be inefficient for large ranges. It is not suitable for sorting non-integer or floating-point values. 23"
"What is a bucket sort, and when is it efficient?","Bucket sort is a sorting algorithm that distributes elements into different ""buckets"" based on their value range, then sorts each bucket individually (usually with another sorting algorithm like insertion sort). It is efficient when the input elements are uniformly distributed across a known range."
What is the time complexity of bucket sort?,"The time complexity of bucket sort is O(n + k), where n is the number of elements and k is the number of buckets. If the elements are uniformly distributed, the sorting within each bucket will be efficient, making bucket sort an efficient algorithm for certain types of inputs."
How do you choose the number of buckets in bucket sort?,"The number of buckets in bucket sort is typically chosen based on the range and distribution of the input data. A general guideline is to choose the number of buckets as O(n), where n is the number of elements, although the optimal number of buckets depends on the input distribution."
What is the average-case time complexity of quicksort?,"The average-case time complexity of quicksort is O(n log n). This occurs when the pivot divides the array into roughly equal parts, leading to efficient sorting."
What are the disadvantages of merge sort?,"The main disadvantage of merge sort is that it requires additional space for storing temporary arrays during the merge process. This makes its space complexity O(n), which can be problematic for large datasets. Additionally, merge sort is not an in-place sorting algorithm."
What is the principle behind the quicksort algorithm?,"The principle behind quicksort is the ""divide and conquer"" approach. The algorithm selects a pivot element, partitions the array into two subarrays (one with elements smaller than the pivot and one with elements greater), and recursively applies the same procedure to each subarray until the array is sorted."
What are the advantages of quicksort over other sorting algorithms?,"The advantages of quicksort include: It is an in-place sorting algorithm, meaning it doesn't require extra memory. It has a fast average-case time complexity of O(n log n).It is often faster in practice than other algorithms like merge sort or heap sort due to smaller constant factors and better cache performance. 24"
What is the primary difference between heap sort and quicksort?,"The primary difference is that heap sort is based on a binary heap and always has a time complexity of O(n log n), while quicksort uses a divide-and- conquer approach with an average-case time complexity of O(n log n) but can degrade to O(n²) in the worst case."
Can quicksort be used to sort linked lists?,"Yes, quicksort can be used to sort linked lists, although it requires some modifications. Instead of using an array index to divide the list into sublists, linked list pointers are used. It still works based on the partitioning and recursive approach of quicksort."
What are the differences between selection sort and insertion sort?,"The main difference is that selection sort selects the minimum (or maximum) element from the unsorted portion of the array and swaps it with the first unsorted element. Insertion sort, on the other hand, builds the sorted portion of the array by inserting elements one by one into their correct position."
What is the primary disadvantage of selection sort?,"The primary disadvantage of selection sort is that it has a time complexity of O(n²), making it inefficient for large datasets. Additionally, it is not adaptive, meaning it does not perform better on nearly sorted arrays."
What is the worst-case time complexity of quicksort?,"The worst-case time complexity of quicksort is O(n²). This occurs when the pivot selected is consistently the smallest or largest element, leading to unbalanced partitions. This results in the algorithm behaving like a simple linear scan of the list, which takes quadratic time."
What is the difference between linear search and binary search?,"The main difference is that linear search checks each element in the array one by one, whereas binary search works on sorted arrays and repeatedly divides the search space in half, making it much faster. Linear search has a time complexity of O(n), while binary search has a time complexity of O(log n)."
What is the time complexity of counting sort in terms of the range of input values?,"The time complexity of counting sort is O(n + k), where n is the number of elements in the input array, and k is the range of the input (the 25 difference between the maximum and minimum element values). Counting sort is efficient when the range k is not too large relative to n."
Why is counting sort not suitable for floating-point numbers?,"Counting sort is not suitable for floating-point numbers because it assumes the input elements are integers, and it uses an array index based on the input values. Floating-point numbers can have decimal places, making it difficult to use as an index in a counting array."
Can merge sort be optimized to use less memory?,"Merge sort can be optimized to use less memory by implementing it in an in-place manner, but this requires significant changes to the algorithm and is generally not as efficient or simple as the traditional method. The standard merge sort requires O(n) additional space for merging."
What are the advantages of using a heap data structure for sorting?,"A heap data structure allows efficient sorting because it provides an efficient way to extract the maximum or minimum element. Heap sort, which uses a binary heap, has a time complexity of O(n log n) and is an in-place algorithm, meaning it doesn't require extra memory like merge sort. However, it is not a stable sort."
What is the difference between a max-heap and a min-heap?,"In a max-heap, the parent node has a value greater than or equal to the values of its children, meaning the maximum element is at the root. In a min- heap, the parent node has a value less than or equal to its children, meaning the minimum element is at the root."
How does quicksort handle duplicate elements in an array?,"Quicksort handles duplicate elements by treating them as any other element during the partitioning phase. If the element is equal to the pivot, it stays in place, and no swaps are needed. Quicksort will still function normally with duplicate elements, although the performance might vary depending on the pivot selection strategy."
How do you improve the performance of quicksort?,"The performance of quicksort can be improved by: Using random pivot selection to avoid worst-case behaviour. Using the ""median of three"" rule to select a pivot, which is often more balanced. Switching to insertion sort for small subarrays, where quicksort’s overhead becomes less efficient. 26"
What are the best and worst cases for quicksort?,"The best and average-case time complexity for quicksort is O(n log n), which occurs when the pivot divides the array roughly in half. The worst-case time complexity is O(n²), which occurs when the pivot is consistently the smallest or largest element."
What is the purpose of the partitioning process in quicksort?,"The partitioning process in quicksort is used to reorder the elements around a pivot such that all elements smaller than the pivot are on its left, and all elements greater than the pivot are on its right. This helps to reduce the problem size and applies the same process recursively to the subarrays."
Why is quicksort not stable?,"Quicksort is not stable because when partitioning the array, elements with equal values may be swapped, changing their relative order. Stability in sorting algorithms means that elements with equal values maintain their original relative order, but quicksort does not guarantee this."
Can quicksort be used on a linked list?,"Yes, quicksort can be used on a linked list, but the partitioning process must be adjusted since a linked list does not allow for direct access to elements like an array. Instead of using array indexing, pointers must be used to partition the linked list and recursively apply quicksort to the sublists."
What is the time complexity of heap sort in the worst case?,"The time complexity of heap sort in the worst case is O(n log n), since both the heapify process and the extraction of the maximum element from the heap take O(log n) time, and this is done n times for each element."
How do you perform a heapify operation in a binary heap?,"The heapify operation in a binary heap is performed by repeatedly checking if a node violates the heap property (i.e., if the parent is greater than or less than its children, depending on whether it's a max-heap or min-heap). If a violation occurs, the node is swapped with its largest (or smallest) child, and the heapify process is applied recursively to the affected subtree."
How does bubble sort work?,"Bubble sort works by repeatedly stepping through the list, comparing adjacent elements, and swapping them if they are in the wrong order. This process is repeated until no more swaps are needed, indicating that the list is sorted. Each pass through the list moves the largest unsorted element to its correct position. 27"
What is the time complexity of insertion sort in the worst case?,"The worst-case time complexity of insertion sort is O(n²). This occurs when the input array is in reverse order, as each element must be compared and shifted through the entire sorted portion of the array."
How does the partition function work in quicksort?,"The partition function in quicksort works by choosing a pivot element and rearranging the elements so that all elements less than the pivot are on its left, and all elements greater than the pivot are on its right. After partitioning, the pivot is placed in its final sorted position, and quicksort is recursively applied to the left and right subarrays."
How does merge sort ensure stable sorting?,"Merge sort is stable because, during the merge step, when two elements have equal values, the one from the left subarray is chosen first. This preserves the relative order of equal elements, making merge sort a stable sorting algorithm."
How can you modify merge sort to work in-place?,"Modifying merge sort to work in-place is possible but more complex. One approach is to merge the two sorted subarrays in-place, without using additional space. This can be done by finding the correct positions for the elements from one subarray and shifting them accordingly. However, this version is less efficient and harder to implement than the standard merge sort."
What is the advantage of bubble sort in practice?,"The main advantage of bubble sort is its simplicity. It is easy to implement and understand, and it can be useful for very small datasets or nearly sorted arrays. However, it is generally inefficient for larger datasets due to its O(n²) time complexity."
What is the space complexity of radix sort?,"The space complexity of radix sort is O(n + k), where n is the number of elements to be sorted and k is the range of the digits (or the number of possible values for each digit). The space is used for storing the temporary count arrays and the output array."
What is the impact of choosing the wrong pivot in quicksort?,"Choosing the wrong pivot in quicksort can lead to an unbalanced partitioning, which causes the algorithm to degrade to its worst-case time complexity of O(n²). For example, if the pivot consistently divides the array into extremely unbalanced subarrays, the recursive depth will be very high, leading to inefficient performance. 28"
How do you implement a priority queue with a binary heap?,"A priority queue can be implemented using a binary heap by maintaining the heap property (either max-heap or min-heap) during insertion and extraction. Insertions take O(log n) time as they require bubbling up the newly inserted element, and extractions also take O(log n) time as they require re-heapifying the heap after removing the root."
What are the trade-offs between quicksort and merge sort?,"The trade-offs between quicksort and merge sort include: Quicksort is generally faster in practice due to lower constant factors and better cache performance. However, it has a worst-case time complexity of O(n²), which can be avoided with good pivot selection strategies. Merge sort guarantees a worst- case time complexity of O(n log n), but it requires extra space for merging the subarrays, which can be a disadvantage when working with large datasets"
What is an array?,An array is a data structure that stores multiple values of the same type in contiguous memory locations.
How do you declare an array in C?,int arr[5]; declares an integer array of size 5.
What is the index of the first element in an array?,The first element in an array has an index of 0.
How do you initialize an array in Python?,"arr = [1, 2, 3, 4, 5]."
How do you find the length of an array in Java?,Using arr.length.
What is a dynamic array?,A dynamic array resizes itself automatically when elements are added or removed.
How do you merge two sorted arrays?,Use the two-pointer technique for O(n) time complexity.
What is the time complexity of inserting an element in an array?,"Best case: O(1), Worst case: O(n). 29"
How do you reverse an array in Python?,arr[::-1].
What is a sparse array?,A sparse array is an array where most elements are zero or empty.
What is a stack?,"A stack is a linear data structure that follows LIFO (Last In, First Out)."
What are the main operations of a stack?,"push(), pop(), peek(), and isEmpty()."
What is stack overflow?,It occurs when the stack exceeds its memory limit.
What is an application of stacks?,Undo/Redo in text editors.
What is a recursive stack?,A stack used to store function calls during recursion.
How do you implement a stack using an array?,Maintain a top pointer and use an array to store elements.
How do you implement a stack using a linked list?,Use a linked list where top points to the head node.
What is the time complexity of stack operations?,O(1) for push and pop.
What is the difference between stack and queue?,"Stack follows LIFO, while Queue follows FIFO."
What is a real-life example of a stack?,"A stack of plates, where the last one placed is removed first."
What is a queue?,"A queue is a linear data structure that follows FIFO (First In, First Out)."
What are the main operations of a queue?,"enqueue(), dequeue(), peek(). 30"
What is a circular queue?,A queue where the last position connects back to the first to reuse space.
What is a priority queue?,A queue where elements are dequeued based on priority.
What is a double-ended queue (Deque)?,A queue where elements can be added or removed from both ends.
What is a real-life example of a queue?,A line at a ticket counter.
How do you implement a queue using a stack?,Use two stacks: one for enqueue and another for dequeue.
What is the time complexity of queue operations?,O(1) for enqueue and dequeue.
What are the applications of queues?,"CPU scheduling, Printer queue, Network packet handling."
What is the difference between queue and stack?,"Stack follows LIFO, while Queue follows FIFO."
What is recursion?,A function that calls itself to solve a smaller subproblem.
What are the two main components of recursion?,Base case and recursive case.
What is infinite recursion?,"When the base case is missing or incorrect, leading to infinite function calls."
What is tail recursion?,A recursion where the recursive call is the last statement in the function.
What are the advantages of recursion?,Simplifies code for complex problems like tree traversal. 31
What are the disadvantages of recursion?,Uses more memory due to function call stack.
How do you calculate factorial using recursion?,def factorial(n): if n == 0: return 1 return n * factorial(n - 1)
What is the Fibonacci sequence using recursion?,def fibonacci(n): if n <= 1: return n return fibonacci(n-1) + fibonacci(n-2)
How can recursion be converted to iteration?,By using loops and stacks explicitly.
What is the recursive depth limit in Python?,"Default limit is 1000, but can be modified using sys.setrecursionlimit()."
What is a linked list?,A data structure where elements (nodes) are connected using pointers.
What are the types of linked lists?,"Singly linked list, Doubly linked list, Circular linked list."
How do you insert a node at the beginning of a linked list?,Create a new node and point it to the existing head.
How do you delete a node from a linked list?,Update the previous node’s pointer to skip the node.
What is the difference between an array and a linked list?,"Arrays have fixed size, while linked lists grow dynamically."
How do you reverse a linked list?,Use pointers to traverse and reverse connections.
What is the time complexity of searching in a linked list?,O(n). 32
What is the head of a linked list?,The first node in the list.
What is the tail of a linked list?,"The last node, pointing to NULL."
What is a circular linked list?,A linked list where the last node connects to the first node.
What is a binary tree?,A tree where each node has at most two children.
What is a binary search tree (BST)?,A binary tree where left subtree has smaller values and right subtree has larger values.
is tree traversal?,"Preorder, Inorder, Postorder."
What is the height of a tree?,The longest path from root to leaf.
What is a balanced tree?,A tree where the height difference between left and right subtrees is at most 1. 33
